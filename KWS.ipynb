{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KWS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quynhu-d/kws/blob/main/KWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhrn5O-qUYZ"
      },
      "source": [
        "# Import and misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meO-Mp9jiAFC",
        "outputId": "1a2b0cbc-fdc7-4952-c914-a0dbc69fafd8"
      },
      "source": [
        "!pip install torchaudio==0.9.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==0.9.1\n",
            "  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.1\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 7.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1->torchaudio==0.9.1) (3.10.0.2)\n",
            "Installing collected packages: torch, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1 torchaudio-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbUpoArCqUYa"
      },
      "source": [
        "from typing import Tuple, Union, List, Callable, Optional\n",
        "from tqdm import tqdm\n",
        "from itertools import islice\n",
        "import pathlib\n",
        "import dataclasses\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchaudio\n",
        "from IPython import display as display_"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812GwLfqqUYf"
      },
      "source": [
        "# Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1DuQIyRqUYf"
      },
      "source": [
        "In this notebook we will implement a model for finding a keyword in a stream.\n",
        "\n",
        "We will implement the version with CRNN because it is easy and improves the model. \n",
        "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PdhApeEh9pH"
      },
      "source": [
        "@dataclasses.dataclass\n",
        "class TaskConfig:\n",
        "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    num_epochs: int = 20\n",
        "    n_mels: int = 40\n",
        "    cnn_out_channels: int = 8\n",
        "    kernel_size: Tuple[int, int] = (5, 20)\n",
        "    stride: Tuple[int, int] = (2, 8)\n",
        "    hidden_size: int = 64\n",
        "    gru_num_layers: int = 2\n",
        "    bidirectional: bool = False\n",
        "    num_classes: int = 2\n",
        "    sample_rate: int = 16000\n",
        "    device: torch.device = torch.device(\n",
        "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sodUd4uWHkP2",
        "outputId": "240ce08d-23dd-48ba-893f-8fe566dfda8e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA1gPmE1h9pI"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2N8zcx9MF1X"
      },
      "source": [
        "#!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
        "!mkdir speech_commands && tar -C speech_commands -xvzf /content/drive/MyDrive/Colab\\ Notebooks/DLA/KWS/speech_commands_v0.01.tar.gz 1> log"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12wBTK0mNUsG"
      },
      "source": [
        "class SpeechCommandDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        transform: Optional[Callable] = None,\n",
        "        path2dir: str = None,\n",
        "        keywords: Union[str, List[str]] = None,\n",
        "        csv: Optional[pd.DataFrame] = None\n",
        "    ):        \n",
        "        self.transform = transform\n",
        "\n",
        "        if csv is None:\n",
        "            path2dir = pathlib.Path(path2dir)\n",
        "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
        "            \n",
        "            all_keywords = [\n",
        "                p.stem for p in path2dir.glob('*')\n",
        "                if p.is_dir() and not p.stem.startswith('_')\n",
        "            ]\n",
        "\n",
        "            triplets = []\n",
        "            for keyword in all_keywords:\n",
        "                paths = (path2dir / keyword).rglob('*.wav')\n",
        "                if keyword in keywords:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
        "                else:\n",
        "                    for path2wav in paths:\n",
        "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
        "            \n",
        "            self.csv = pd.DataFrame(\n",
        "                triplets,\n",
        "                columns=['path', 'keyword', 'label']\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.csv = csv\n",
        "    \n",
        "    def __getitem__(self, index: int):\n",
        "        instance = self.csv.iloc[index]\n",
        "\n",
        "        path2wav = instance['path']\n",
        "        wav, sr = torchaudio.load(path2wav)\n",
        "        wav = wav.sum(dim=0)\n",
        "        \n",
        "        if self.transform:\n",
        "            wav = self.transform(wav)\n",
        "\n",
        "        return {\n",
        "            'wav': wav,\n",
        "            'keywors': instance['keyword'],\n",
        "            'label': instance['label']\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1rVkT81Pk90"
      },
      "source": [
        "dataset = SpeechCommandDataset(\n",
        "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DFwhAXdfQLIA",
        "outputId": "039745ee-5f19-4a9d-9551-5a977a504a9b"
      },
      "source": [
        "dataset.csv.sample(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>keyword</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50905</th>\n",
              "      <td>speech_commands/no/8523766b_nohash_1.wav</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9698</th>\n",
              "      <td>speech_commands/zero/7b301939_nohash_1.wav</td>\n",
              "      <td>zero</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1693</th>\n",
              "      <td>speech_commands/on/29fb33da_nohash_2.wav</td>\n",
              "      <td>on</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>speech_commands/four/b1f8326d_nohash_0.wav</td>\n",
              "      <td>four</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19276</th>\n",
              "      <td>speech_commands/yes/3ae5c04f_nohash_1.wav</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             path keyword  label\n",
              "50905    speech_commands/no/8523766b_nohash_1.wav      no      0\n",
              "9698   speech_commands/zero/7b301939_nohash_1.wav    zero      0\n",
              "1693     speech_commands/on/29fb33da_nohash_2.wav      on      0\n",
              "6840   speech_commands/four/b1f8326d_nohash_0.wav    four      0\n",
              "19276   speech_commands/yes/3ae5c04f_nohash_1.wav     yes      0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxfDJw1qUYi"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmkxPWQqUYe"
      },
      "source": [
        "class AugsCreation:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.background_noises = [\n",
        "            'speech_commands/_background_noise_/white_noise.wav',\n",
        "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
        "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
        "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
        "            'speech_commands/_background_noise_/pink_noise.wav',\n",
        "            'speech_commands/_background_noise_/running_tap.wav'\n",
        "        ]\n",
        "\n",
        "        self.noises = [\n",
        "            torchaudio.load(p)[0].squeeze()\n",
        "            for p in self.background_noises\n",
        "        ]\n",
        "\n",
        "    def add_rand_noise(self, audio):\n",
        "\n",
        "        # randomly choose noise\n",
        "        noise_num = torch.randint(low=0, high=len(\n",
        "            self.background_noises), size=(1,)).item()\n",
        "        noise = self.noises[noise_num]\n",
        "\n",
        "        noise_level = torch.Tensor([1])  # [0, 40]\n",
        "\n",
        "        noise_energy = torch.norm(noise)\n",
        "        audio_energy = torch.norm(audio)\n",
        "        alpha = (audio_energy / noise_energy) * \\\n",
        "            torch.pow(10, -noise_level / 20)\n",
        "\n",
        "        start = torch.randint(\n",
        "            low=0,\n",
        "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
        "            size=(1,)\n",
        "        ).item()\n",
        "        noise_sample = noise[start: start + audio.size(0)]\n",
        "\n",
        "        audio_new = audio + alpha * noise_sample\n",
        "        audio_new.clamp_(-1, 1)\n",
        "        return audio_new\n",
        "\n",
        "    def __call__(self, wav):\n",
        "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
        "        augs = [\n",
        "            lambda x: x,\n",
        "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
        "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
        "            lambda x: self.add_rand_noise(x)\n",
        "        ]\n",
        "\n",
        "        return augs[aug_num](wav)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClWThxyYh9pM"
      },
      "source": [
        "indexes = torch.randperm(len(dataset))\n",
        "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
        "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
        "\n",
        "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
        "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3m_TgiAjAn0"
      },
      "source": [
        "train_df.to_csv('train_df.csv')\n",
        "val_df.to_csv('val_df.csv')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDPLht5fqUYe"
      },
      "source": [
        "# Sample is a dict of utt, word and label\n",
        "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
        "val_set = SpeechCommandDataset(csv=val_df)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbPDqd6qUYj"
      },
      "source": [
        "### Sampler for oversampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfnjRKo2qUYj"
      },
      "source": [
        "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
        "\n",
        "def get_sampler(target):\n",
        "    class_sample_count = np.array(\n",
        "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in target])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weigth = samples_weight.float()\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "    return sampler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM8gLmHeqUYj"
      },
      "source": [
        "train_sampler = get_sampler(train_set.csv['label'].values)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyBqbxp0h9pO"
      },
      "source": [
        "class Collator:\n",
        "    \n",
        "    def __call__(self, data):\n",
        "        wavs = []\n",
        "        labels = []    \n",
        "\n",
        "        for el in data:\n",
        "            wavs.append(el['wav'])\n",
        "            labels.append(el['label'])\n",
        "\n",
        "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
        "        wavs = pad_sequence(wavs, batch_first=True)    \n",
        "        labels = torch.Tensor(labels).long()\n",
        "        return wavs, labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8G9xPRVqUYk"
      },
      "source": [
        "###  Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wGBMcQiqUYk"
      },
      "source": [
        "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
        "                          shuffle=False, collate_fn=Collator(),\n",
        "                          sampler=train_sampler,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
        "                        shuffle=False, collate_fn=Collator(),\n",
        "                        num_workers=2, pin_memory=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlsn6cpqUYk"
      },
      "source": [
        "### Creating MelSpecs on GPU for speeeed: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRXMt6it56fW"
      },
      "source": [
        "class LogMelspec:\n",
        "\n",
        "    def __init__(self, is_train, config):\n",
        "        # with augmentations\n",
        "        if is_train:\n",
        "            self.melspec = nn.Sequential(\n",
        "                torchaudio.transforms.MelSpectrogram(\n",
        "                    sample_rate=config.sample_rate,\n",
        "                    n_fft=400,\n",
        "                    win_length=400,\n",
        "                    hop_length=160,\n",
        "                    n_mels=config.n_mels\n",
        "                ),\n",
        "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
        "            ).to(config.device)\n",
        "\n",
        "        # no augmentations\n",
        "        else:\n",
        "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
        "                sample_rate=config.sample_rate,\n",
        "                n_fft=400,\n",
        "                win_length=400,\n",
        "                hop_length=160,\n",
        "                n_mels=config.n_mels\n",
        "            ).to(config.device)\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        # already on device\n",
        "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqkz4_gn8BiF"
      },
      "source": [
        "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
        "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhk5C_xkkP_q",
        "outputId": "61d3fe21-d8e2-4811-cae6-ccbc714d55fc"
      },
      "source": [
        "# melspec_train(next(iter(train_loader))[0].to('cuda')).shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 40, 101])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoAxmihY8yxr"
      },
      "source": [
        "### Quality measurement functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euwD1UyuqUYk"
      },
      "source": [
        "# FA - true: 0, model: 1\n",
        "# FR - true: 1, model: 0\n",
        "\n",
        "def count_FA_FR(preds, labels):\n",
        "    FA = torch.sum(preds[labels == 0])\n",
        "    FR = torch.sum(labels[preds == 0])\n",
        "    \n",
        "    # torch.numel - returns total number of elements in tensor\n",
        "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHBUrkT1qUYk"
      },
      "source": [
        "def get_au_fa_fr(probs, labels):\n",
        "    sorted_probs, _ = torch.sort(probs)\n",
        "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "        \n",
        "    FAs, FRs = [], []\n",
        "    for prob in sorted_probs:\n",
        "        preds = (probs >= prob) * 1\n",
        "        FA, FR = count_FA_FR(preds, labels)        \n",
        "        FAs.append(FA)\n",
        "        FRs.append(FR)\n",
        "    # plt.plot(FAs, FRs)\n",
        "    # plt.show()\n",
        "\n",
        "    # ~ area under curve using trapezoidal rule\n",
        "    return -np.trapz(FRs, x=FAs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcEP5cEZqUYl"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cP_pFIsy5p2",
        "outputId": "38bed635-b9c8-4cc3-a68b-872fbd526c02"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.energy = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        energy = self.energy(input)\n",
        "        alpha = torch.softmax(energy, dim=-2)\n",
        "        return (input * alpha).sum(dim=-2)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TaskConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1, out_channels=config.cnn_out_channels,\n",
        "                kernel_size=config.kernel_size, stride=config.stride\n",
        "            ),\n",
        "            nn.Flatten(start_dim=1, end_dim=2),\n",
        "        )\n",
        "\n",
        "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
        "            config.stride[0] + 1\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.gru_num_layers,\n",
        "            dropout=0.1,\n",
        "            bidirectional=config.bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.attention = Attention(config.hidden_size)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        input = input.unsqueeze(dim=1)\n",
        "        conv_output = self.conv(input).transpose(-1, -2)\n",
        "        gru_output, _ = self.gru(conv_output)\n",
        "        contex_vector = self.attention(gru_output)\n",
        "        output = self.classifier(contex_vector)\n",
        "        return output\n",
        "\n",
        "config = TaskConfig()\n",
        "model = CRNN(config)\n",
        "model"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmmSFvWaqUYn"
      },
      "source": [
        "def train_epoch(model, opt, loader, log_melspec, device):\n",
        "    model.train()\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # run model # with autocast():\n",
        "        logits = model(batch)\n",
        "        # we need probabilities so we use softmax & CE separately\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIeRbn4tqUYo"
      },
      "source": [
        "@torch.no_grad()\n",
        "def validation(model, loader, log_melspec, device):\n",
        "    model.eval()\n",
        "\n",
        "    val_losses, accs, FAs, FRs = [], [], [], []\n",
        "    all_probs, all_labels = [], []\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        output = model(batch)\n",
        "        # we need probabilities so we use softmax & CE separately\n",
        "        probs = F.softmax(output, dim=-1)\n",
        "        loss = F.cross_entropy(output, labels)\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        all_probs.append(probs[:, 1].cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "        val_losses.append(loss.item())\n",
        "        accs.append(\n",
        "            torch.sum(argmax_probs == labels).item() /  # ???\n",
        "            torch.numel(argmax_probs)\n",
        "        )\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        FAs.append(FA)\n",
        "        FRs.append(FR)\n",
        "\n",
        "    # area under FA/FR curve for whole loader\n",
        "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
        "    return au_fa_fr"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpyvKwp0k3IU"
      },
      "source": [
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "history = defaultdict(list)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSNW-nZCJ4Q0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8sVpHNoocgA",
        "outputId": "bfcb36fa-df3b-41f6-d545-179cee103551"
      },
      "source": [
        "config = TaskConfig()\n",
        "model = CRNN(config).to(config.device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "opt = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config.learning_rate,\n",
        "    weight_decay=config.weight_decay\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRNN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
            "    (1): Flatten(start_dim=1, end_dim=2)\n",
            "  )\n",
            "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (attention): Attention(\n",
            "    (energy): Sequential(\n",
            "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zedXm9dmINAE",
        "outputId": "74faed24-a304-417d-be0d-5d616833c2bf"
      },
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70443"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt2kjqC-IobK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "32oooz4lqUYo",
        "scrolled": false,
        "outputId": "3b75358f-c56f-4a51-86d9-73b3b82f910d"
      },
      "source": [
        "# TRAIN\n",
        "\n",
        "for n in range(TaskConfig.num_epochs):\n",
        "\n",
        "    train_epoch(model, opt, train_loader,\n",
        "                melspec_train, config.device)\n",
        "\n",
        "    au_fa_fr = validation(model, val_loader,\n",
        "                          melspec_val, config.device)\n",
        "    history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "    clear_output()\n",
        "    plt.plot(history['val_metric'])\n",
        "    plt.ylabel('Metric')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    print('END OF EPOCH', n)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END OF EPOCH 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9nfdPg_agAZ",
        "outputId": "3f7386fc-44c8-4b2e-cd09-5b92acc6abad"
      },
      "source": [
        "history"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'val_metric': [0.0003598132814037343,\n",
              "              0.0001798022086191975,\n",
              "              8.506739076889015e-05,\n",
              "              7.583559466089485e-05,\n",
              "              7.941015566198676e-05,\n",
              "              4.6833313416643275e-05,\n",
              "              4.044206995726192e-05,\n",
              "              4.555625823428323e-05,\n",
              "              2.8859060102304646e-05,\n",
              "              2.690767204327785e-05,\n",
              "              2.7176211684428326e-05,\n",
              "              2.723588716023954e-05,\n",
              "              2.050449348873424e-05,\n",
              "              1.999725194433889e-05,\n",
              "              1.5157570856049174e-05,\n",
              "              1.6506236609382685e-05,\n",
              "              1.7013478153778034e-05,\n",
              "              1.9454205114456816e-05,\n",
              "              1.82965008837192e-05,\n",
              "              1.9027525462406615e-05]})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHMNioQDao2n"
      },
      "source": [
        "torch.save(model.state_dict(), 'base_model')\n",
        "torch.save(opt.state_dict(), 'base_opt')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGKcPdpf83Dj"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITAEWteC84dg"
      },
      "source": [
        "def count_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    return sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDzF1XnsTBgd"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "class Timer:\n",
        "\n",
        "    def __init__(self, name: str, verbose=False):\n",
        "        self.name = name\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.t = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.t = time.time() - self.t\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"{self.name.capitalize()} | Elapsed time : {self.t:.2f}\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NFCl1lRTHO9",
        "outputId": "cddff3e0-ed6a-4fb3-eaec-a7657b3c59a7"
      },
      "source": [
        "!pip install thop"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from thop) (1.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->thop) (3.10.0.2)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.0.31.post2005241907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZLGlDPCTWcO",
        "outputId": "4009503e-9418-4a05-d594-c9720455e3ef"
      },
      "source": [
        "melspec_train(iter(train_loader).next()[0].to(config.device)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 40, 101])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M6HRb8XTE_4",
        "outputId": "7565f35d-2b0d-487a-8891-4068d388492c"
      },
      "source": [
        "from thop import profile        \n",
        "profile(CRNN(config), (torch.randn(128, 40, 101), ))  # -> (6.0 MACs, 3.0 parameters)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119527424.0, 70443.0)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Al8FP7Us64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f549bc-420b-4098-98e9-d3bf7a986832"
      },
      "source": [
        "def get_size_in_megabytes(model):\n",
        "    num_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "    param_size = next(model.parameters()).element_size()\n",
        "    return (num_params * param_size) / (2 ** 20)\n",
        "\n",
        "get_size_in_megabytes(model)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2687187194824219"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyuC9Rl0a6A7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBw4VZXua6ba"
      },
      "source": [
        "# Streaming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFCOEWhJCxh6"
      },
      "source": [
        "class StreamingCRNN(CRNN):\n",
        "    def __init__(self, config, max_window_length):\n",
        "        self.max_window_length = max_window_length\n",
        "        super().__init__(config)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NJjHcPtQsx"
      },
      "source": [
        "# Dark Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmjsaTHdtl4u"
      },
      "source": [
        "def train_epoch_w_teacher(student, teacher, opt, loader, log_melspec, device, temp=20, alpha=.5):\n",
        "    student.train()\n",
        "    teacher.train()\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # run model # with autocast():\n",
        "        teacher_logits = teacher(batch).detach()\n",
        "        student_logits = student(batch)\n",
        "\n",
        "        soft_labels = F.softmax(teacher_logits / temp, dim=-1)\n",
        "        soft_preds = F.softmax(student_logits / temp, dim=-1)\n",
        "        distill_loss = F.kl_div(soft_preds.log(), soft_labels, reduction='sum')    # KL divergence\n",
        "\n",
        "        hard_probs = F.softmax(student_logits, dim=-1)\n",
        "        student_loss = F.cross_entropy(student_logits, labels)\n",
        "\n",
        "        loss = alpha * student_loss + (1 - alpha) * distill_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5)\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        # logging\n",
        "        argmax_probs = torch.argmax(hard_probs, dim=-1)\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def train_w_teacher(student, teacher, config, opt, loaders, log_melspec, temp=20, alpha=.5):\n",
        "    train_loader, val_loader = loaders\n",
        "    melspec_train, melspec_val = log_melspec\n",
        "    history = defaultdict(list)\n",
        "    for n in range(config.num_epochs):\n",
        "\n",
        "        train_epoch_w_teacher(\n",
        "            student, teacher, opt, train_loader, melspec_train, config.device, temp, alpha\n",
        "        )\n",
        "\n",
        "        au_fa_fr = validation(student, val_loader, melspec_val, config.device)\n",
        "        history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "        clear_output()\n",
        "        plt.plot(history['val_metric'])\n",
        "        plt.ylabel('Metric')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "        print('END OF EPOCH %d / %d' % (n, config.num_epochs))\n",
        "        \n",
        "        if (au_fa_fr - 1.1 * 5e-5) <= 5e-6:\n",
        "            break\n",
        "    return history"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEKpIzII8C-V",
        "outputId": "84bb270b-2e69-480e-82b9-30833c9f4ee1"
      },
      "source": [
        "model"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ9r0rxp8FCf",
        "outputId": "3ef7f8fd-ff7e-41f9-bd04-61567f612d17"
      },
      "source": [
        "student_config = TaskConfig\n",
        "student_config.hidden_size = 16\n",
        "student_config.cnn_out_channels = 4\n",
        "student_config.num_epochs = 50\n",
        "\n",
        "student_model = CRNN(student_config).to(student_config.device)\n",
        "student_opt = torch.optim.Adam(\n",
        "    student_model.parameters(),\n",
        "    lr=student_config.learning_rate,\n",
        "    weight_decay=student_config.weight_decay\n",
        ")\n",
        "print('Number of params %d' % count_parameters(student_model))\n",
        "student_model"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of params 6679\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 4, kernel_size=(5, 20), stride=(2, 8))\n",
              "    (1): Flatten(start_dim=1, end_dim=2)\n",
              "  )\n",
              "  (gru): GRU(72, 16, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (attention): Attention(\n",
              "    (energy): Sequential(\n",
              "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=16, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "YqY0_5DO-P-n",
        "outputId": "e7927563-0969-4430-c67a-b369ebdac3e4"
      },
      "source": [
        "res_distill = train_w_teacher(student_model, model, student_config, student_opt, \n",
        "                (train_loader, val_loader), (melspec_train, melspec_val))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END OF EPOCH 25 / 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fecvbAqITF1",
        "outputId": "ff8be3ca-1be2-4daf-ccf1-e0a6f7f153d4"
      },
      "source": [
        "res_distill['val_metric'][-1]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.731531074288358e-05"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2r6Zu9IpoF",
        "outputId": "499e3f25-e8b3-45f9-9747-746216df6053"
      },
      "source": [
        "model.eval()\n",
        "with Timer('Base model', verbose=True):\n",
        "    model(melspec_val(next(iter(val_loader))[0].to(config.device)))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model | Elapsed time : 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in9mKlcyKZn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6L22HCwKL71",
        "outputId": "18f7b8d9-6f74-4f27-f045-f41a66022ed1"
      },
      "source": [
        "student_model.eval()\n",
        "with Timer('Student model', verbose=True):\n",
        "    student_model(melspec_val(next(iter(val_loader))[0].to(config.device)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model | Elapsed time : 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4DcgiH3LH7d"
      },
      "source": [
        "torch.save(student_model.state_dict(), 'student_model_1')\n",
        "torch.save(student_opt.state_dict(), 'student_opt_1')"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMele8jJNkTB",
        "outputId": "b994da18-6f0d-4081-f073-bf4a7868848e"
      },
      "source": [
        "base_macs, base_n_params = profile(CRNN(config), (torch.randn(1,40,101),))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZWOv2OvKaf8",
        "outputId": "4cf1c6c3-b1bd-4d73-e624-5d53229b63d6"
      },
      "source": [
        "student_macs, student_n_params = profile(CRNN(student_config), (torch.randn(1, 40, 101),))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Attention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.CRNN'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGL7tw1NHAQ",
        "outputId": "e789cb70-da4f-4700-ab52-5a62cb480269"
      },
      "source": [
        "base_mb_sz = get_size_in_megabytes(model)\n",
        "print(base_mb_sz)\n",
        "student_mb_sz = get_size_in_megabytes(student_model)\n",
        "print(student_mb_sz)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2687187194824219\n",
            "0.025478363037109375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra7OxqnyVNpz",
        "outputId": "bd7ef747-b2ce-4fb1-9fed-67b8fb5e716f"
      },
      "source": [
        "def config_to_dict(config, hparam_n = 15):\n",
        "    return {key: config.__dict__[key] for key in sorted(config.__dict__.keys())[-hparam_n:]}\n",
        "config_to_dict(config)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'bidirectional': False,\n",
              " 'cnn_out_channels': 8,\n",
              " 'device': device(type='cuda', index=0),\n",
              " 'gru_num_layers': 2,\n",
              " 'hidden_size': 64,\n",
              " 'kernel_size': (5, 20),\n",
              " 'keyword': 'sheila',\n",
              " 'learning_rate': 0.0003,\n",
              " 'n_mels': 40,\n",
              " 'num_classes': 2,\n",
              " 'num_epochs': 20,\n",
              " 'sample_rate': 16000,\n",
              " 'stride': (2, 8),\n",
              " 'weight_decay': 1e-05}"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "KumMqRSBN_xt",
        "outputId": "9786209d-8c67-4447-a8d8-a7cc98cd26c8"
      },
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame(columns=['SETTING', 'MACS', 'MB_SZ', 'N_PARAMS', 'METRIC'])\n",
        "results_df = results_df.append(\n",
        "    {\n",
        "        **{\n",
        "        'SETTING': 'Base model', \n",
        "        'MACS': base_macs, 'MB_SZ': base_mb_sz, 'N_PARAMS': base_n_params, \n",
        "        'METRIC': history['val_metric'][-1]\n",
        "        },\n",
        "        **config_to_dict(config)\n",
        "    }, \n",
        "    ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SETTING</th>\n",
              "      <th>MACS</th>\n",
              "      <th>MB_SZ</th>\n",
              "      <th>N_PARAMS</th>\n",
              "      <th>METRIC</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>bidirectional</th>\n",
              "      <th>cnn_out_channels</th>\n",
              "      <th>device</th>\n",
              "      <th>gru_num_layers</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>keyword</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_mels</th>\n",
              "      <th>num_classes</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>stride</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Base model</td>\n",
              "      <td>933808.0</td>\n",
              "      <td>0.268719</td>\n",
              "      <td>70443.0</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>(5, 20)</td>\n",
              "      <td>sheila</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>(2, 8)</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      SETTING      MACS     MB_SZ  ...  sample_rate  stride  weight_decay\n",
              "0  Base model  933808.0  0.268719  ...      16000.0  (2, 8)       0.00001\n",
              "\n",
              "[1 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "rxdFWYcRPiOz",
        "outputId": "e458d472-55a4-481c-a914-c9fb5091303a"
      },
      "source": [
        "results_df = results_df.append(\n",
        "    {\n",
        "        **{\n",
        "            'SETTING': 'Dark Knowledge Distillation',\n",
        "            'MACS': student_macs, 'MB_SZ': student_mb_sz, 'N_PARAMS': student_n_params, \n",
        "            'METRIC': res_distill['val_metric'][-1]\n",
        "        },\n",
        "        **config_to_dict(student_config) \n",
        "    },\n",
        "    ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SETTING</th>\n",
              "      <th>MACS</th>\n",
              "      <th>MB_SZ</th>\n",
              "      <th>N_PARAMS</th>\n",
              "      <th>METRIC</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>bidirectional</th>\n",
              "      <th>cnn_out_channels</th>\n",
              "      <th>device</th>\n",
              "      <th>gru_num_layers</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>keyword</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_mels</th>\n",
              "      <th>num_classes</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>stride</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Base model</td>\n",
              "      <td>933808.0</td>\n",
              "      <td>0.268719</td>\n",
              "      <td>70443.0</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>(5, 20)</td>\n",
              "      <td>sheila</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>(2, 8)</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dark Knowledge Distillation</td>\n",
              "      <td>150952.0</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>6679.0</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>(5, 20)</td>\n",
              "      <td>sheila</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>(2, 8)</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       SETTING      MACS  ...  stride  weight_decay\n",
              "0                   Base model  933808.0  ...  (2, 8)       0.00001\n",
              "1  Dark Knowledge Distillation  150952.0  ...  (2, 8)       0.00001\n",
              "\n",
              "[2 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJC2SyTDRA-X"
      },
      "source": [
        "results_df.to_csv('drive/MyDrive/Colab Notebooks/DLA/KWS/kws_experiments.csv', index=False)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "CSD3pwawRtBT",
        "outputId": "f84bf408-34d0-42d3-a804-b4b93d77d46a"
      },
      "source": [
        "pd.read_csv('drive/MyDrive/Colab Notebooks/DLA/KWS/kws_experiments.csv')"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SETTING</th>\n",
              "      <th>MACS</th>\n",
              "      <th>MB_SZ</th>\n",
              "      <th>N_PARAMS</th>\n",
              "      <th>METRIC</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>bidirectional</th>\n",
              "      <th>cnn_out_channels</th>\n",
              "      <th>device</th>\n",
              "      <th>gru_num_layers</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>keyword</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_mels</th>\n",
              "      <th>num_classes</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>stride</th>\n",
              "      <th>weight_decay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Base model</td>\n",
              "      <td>933808.0</td>\n",
              "      <td>0.268719</td>\n",
              "      <td>70443.0</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>(5, 20)</td>\n",
              "      <td>sheila</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>(2, 8)</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dark Knowledge Distillation</td>\n",
              "      <td>150952.0</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>6679.0</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>cuda:0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>(5, 20)</td>\n",
              "      <td>sheila</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>(2, 8)</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       SETTING      MACS  ...  stride  weight_decay\n",
              "0                   Base model  933808.0  ...  (2, 8)       0.00001\n",
              "1  Dark Knowledge Distillation  150952.0  ...  (2, 8)       0.00001\n",
              "\n",
              "[2 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    }
  ]
}